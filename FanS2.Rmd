---
title: "Fantasy Study 2 Analyses"
author: "Aki Gormezano and Jason Burns"
date: "08.15.2022"
output: github_document
---

## libraries
```{r}
library(tidyverse)
library(haven)
library(readxl)
library(psych)
library(lavaan)
```

## data
```{r}
#Prolific participants with usable data
prolific_key <- 
"Fantasy Prolific_Contact_Spreadsheet.csv" %>% 
  read_csv(n_max = 599) %>% 
  filter(
    `Both Fantasies?` == "Y" &
    `Sensical Answers?` == "Y" &
    `Joke Answers?` == "N" #&
    #`Gender/Sex` != "un"
  ) %>% 
  rename(
    ID = `Prolific ID`,
    GenderSex = `Gender/Sex`,
    SexualOrientation = `Sexual Orientation`
    ) %>% 
  select(ID, GenderSex, SexualOrientation)

#Community participants with usable data
community_key <- 
"Fantasy Community_Contact_Spreadsheet.csv" %>% 
  read_csv(n_max = 1822) %>% 
  filter(
    `Both Fantasies?` == "Y" &
    `Sensical Answers?` == "Y" &
    `Joke Answers?` == "N" #&
    #`Gender/Sex` != "un"
  ) %>% 
  rename(
    GenderSex = `Gender/Sex`,
    SexualOrientation = `Sexual Orientation`
    ) %>% 
  select(ID, GenderSex, SexualOrientation)

full_key <- full_join(
  x = prolific_key,
  y = community_key,
  by = colnames(prolific_key)
) %>% 
  rename_with(
    .cols = c("GenderSex","SexualOrientation"),
    .fn = ~paste(.,"_MajMin",sep="")
    )
```

```{r}
#prolific background data
col_names <- names(read_csv("FanS2 Prolific Background Data.csv", n_max = 0)) #pre-defines the column names
prolific_background_data <- "FanS2 Prolific Background Data.csv" %>% read_csv(col_names = col_names, skip = 3) #skips the header + those two useless rows. 

#community background data
col_names <- names(read_csv("FanS2 Community Background Data.csv", n_max = 0)) #pre-defines the column names
community_background_data <- "FanS2 Community Background Data.csv" %>% read_csv(col_names = col_names, skip = 3) #skips the header + those two useless rows. 
```

```{r}
#prolific main data 
col_names <- names(read_csv("FanS2 Prolific Main Data.csv", n_max = 0)) #pre-defines the column names
prolific_main_data <- "FanS2 Prolific Main Data.csv" %>% read_csv(col_names = col_names, skip = 3)  #skips the header + those two useless rows. 

#community main data
col_names <- names(read_csv("FanS2 Community Main Data.csv", n_max = 0)) #pre-defines the column names
community_main_data <- "FanS2 Community Main Data.csv" %>% read_csv(col_names = col_names, skip = 3)  #skips the header + those two useless rows. 

```

```{r}
#main full
main_data <- full_join(
  x = prolific_main_data %>% rename(ID = PROLIFIC_PID),
  y = community_main_data %>% rename(ID = PID)
  ) %>% 
  rename_with(
    .cols =  c(
      "StartDate", "EndDate", "Status", "Progress", "Duration (in seconds)", "Finished", "RecordedDate", "ResponseId","DistributionChannel", "UserLanguage", "consent", "consentquotes", "birthyear", "times", "noread", "noreadwhich", "jokes", "jokeswhich", "howhear", "Checked"
      ),
    .fn = ~paste("MAIN_",.,sep="")
    )
```

```{r}
#background_full
background_data <- full_join(
  x = prolific_background_data %>% rename(ID = PROLIFIC_PID),
  y = community_background_data %>% rename(ID = PID)
  ) %>% 
  rename_with(
    .cols =  c(
"StartDate", "EndDate", "Status", "Progress", "Duration (in seconds)", "Finished", "RecordedDate", "ResponseId","DistributionChannel", "UserLanguage","consent","Comments1", "comments2", "BirthYear", "SurveyTimes", "Attention", "Attention_TEXT", "Joking", "Joking_Text", "Emotion", "maininterest", "Checked"
      ),
    .fn = ~paste("BACKGROUND_",.,sep="")
    )

```

```{r}
usable_data <- 
  left_join(
    x = full_key,
    y = background_data,
    by = "ID"
    ) %>% 
  left_join(
    x = .,
    y = main_data,
    by = "ID"
  )
```

# Data sets for raffle winners

## Background raffle winners (pre-cutoff)

```{r}
#community background pre-cutoff pool
Pre_BackgroundRaffle_Pool <- "Fantasy Community_Contact_Spreadsheet.csv" %>% 
  read_csv(n_max = 1822) %>% 
  mutate(
    row = seq(from = 1, to = nrow(.), by = 1)
  ) %>% 
  relocate(row, .before = Email) %>% 
  filter(
    row <=1410,
    `Payment Eligible` == "Y" 
    ) %>% 
  select(
    ID,
    Email
  )

```

```{r}

#total number of winners

#total number of eligible participants divided by 14
winners.raw <- nrow(Pre_BackgroundRaffle_Pool)/10

#total number of winners to choose

winners.choose <- ceiling(winners.raw)

#print message
message("there will be ", winners.choose, " background pre-cutoff winners")

```

```{r}
#community background pre-cutoff winners
set.seed(1235)
Pre_BackgroundRaffle_Winners <- sample(
  x = Pre_BackgroundRaffle_Pool$ID, #the list of email addresses
  size = winners.choose, #the number of winners we decided on
  replace = FALSE #sample without replacement so the same person doesn't win twice. 
  )

for (i in 1:winners.choose){
  message("winner number ", i, " is ", Pre_BackgroundRaffle_Winners[i])
}

```

```{r}
# Round 1
col_names <- names(read_csv("FanS2 Community Background Payment Info.csv", n_max = 0)) #pre-defines the column names
payment_info <- "FanS2 Community Background Payment Info.csv" %>% read_csv(col_names = col_names, skip = 3) #skips the header + those two useless rows. 

payment_info <- payment_info %>% 
  rename(ID = PID) %>% 
  mutate(
    contact = case_when(
      country_which == "USA" ~ `payment_contact...16`,
      country_which == "Canada" ~ `payment_contact...14`
    ),
    preference = case_when(
      country_which == "USA" ~ USpayment_type,
      country_which == "Canada" ~ CApayment_type
    )
  ) %>% 
  select(
    ID, 
    country_which, 
    contact,
    preference
    )

tibble(ID = Pre_BackgroundRaffle_Winners) %>% 
  left_join(
    x = .,
    y = payment_info,
    by = "ID"
    ) %>% 
  write_csv(
    file = "FanS2 Pre-cutoff background raffle winners R1.csv"
    )

Pre_BackgroundRaffle_Winners_R1 <- 
  "FanS2 Pre-cutoff background raffle winners revised.csv" %>% 
  read_csv() %>% 
  filter(!is.na(preference)) 
```

```{r}
#round 2 pool

'%!in%' <- function(x,y)!('%in%'(x,y))

Pre_BackgroundRaffle_Pool_R2 <- "Fantasy Community_Contact_Spreadsheet.csv" %>% 
  read_csv(n_max = 1822) %>% 
  mutate(
    row = seq(from = 1, to = nrow(.), by = 1)
  ) %>% 
  relocate(row, .before = Email) %>% 
  filter(
    row <=1410,
    `Payment Eligible` == "Y",
    ID %!in% Pre_BackgroundRaffle_Winners
    ) %>% 
  select(
    ID,
    Email
  )

```

```{r}
#total number of winners for round 2

#total number of eligible participants divided by 14
winners.raw <- nrow(Pre_BackgroundRaffle_Pool)/10 

#total number of winners to choose

winners.choose <- ceiling(winners.raw) - nrow(Pre_BackgroundRaffle_Winners_R1)

#print message
message("there will be ", winners.choose, " round 2 background pre-cutoff winners")

```

```{r}
#round 2 draw
set.seed(54321)
Pre_BackgroundRaffle_Winners_R2 <- sample(
  x = Pre_BackgroundRaffle_Pool_R2$ID, #the list of email addresses
  size = winners.choose, #the number of winners we decided on
  replace = FALSE #sample without replacement so the same person doesn't win twice. 
  )

for (i in 1:winners.choose){
  message("R2 winner number ", i, " is ", Pre_BackgroundRaffle_Winners_R2[i])
}

```

```{r}
#add R2 payment info
tibble(ID = Pre_BackgroundRaffle_Winners_R2) %>% 
  left_join(
    x = .,
    y = payment_info,
    by = "ID"
    ) %>% 
  write_csv(
    file = "FanS2 Pre-cutoff background raffle winners R2.csv"
    )

Pre_BackgroundRaffle_Winners_R1_R2 <-
  Pre_BackgroundRaffle_Winners_R1 %>% 
  full_join(
    x = .,
    y = "FanS2 Pre-cutoff background raffle winners R2 revised.csv" %>% 
      read_csv() %>% 
      filter(!is.na(preference)) 
    )

```

```{r}
#round 3 pool

Pre_BackgroundRaffle_Pool_R3 <- "Fantasy Community_Contact_Spreadsheet.csv" %>% 
  read_csv(n_max = 1822) %>% 
  mutate(
    row = seq(from = 1, to = nrow(.), by = 1)
  ) %>% 
  relocate(row, .before = Email) %>% 
  filter(
    row <=1410,
    `Payment Eligible` == "Y",
    ID %!in% Pre_BackgroundRaffle_Winners,
    ID %!in% Pre_BackgroundRaffle_Winners_R2
    ) %>% 
  select(
    ID,
    Email
  )

```

```{r}
#total number of winners for round 3

#total number of eligible participants divided by 14
winners.raw <- nrow(Pre_BackgroundRaffle_Pool)/10 

#total number of winners to choose

winners.choose <- ceiling(winners.raw) - nrow(Pre_BackgroundRaffle_Winners_R1_R2)

#print message
message("there will be ", winners.choose, " 'round 3' background pre-cutoff winners")

```

```{r}
#round 3 draw
set.seed(6521)
Pre_BackgroundRaffle_Winners_R3 <- sample(
  x = Pre_BackgroundRaffle_Pool_R3$ID, #the list of email addresses
  size = winners.choose, #the number of winners we decided on
  replace = FALSE #sample without replacement so the same person doesn't win twice. 
  )

for (i in 1:winners.choose){
  message("R3 winner number ", i, " is ", Pre_BackgroundRaffle_Winners_R3[i])
}

```

```{r}
#add R3 payment info
Pre_BackgroundRaffle_Winners_R3 <- tibble(ID = Pre_BackgroundRaffle_Winners_R3) %>% 
  left_join(
    x = .,
    y = payment_info,
    by = "ID"
    )

Pre_BackgroundRaffle_Winners_R1_R2_R3 <- Pre_BackgroundRaffle_Winners_R1_R2 %>% 
  full_join(
    x = .,
    y = Pre_BackgroundRaffle_Winners_R3,
    by = c("ID", "country_which", "contact", "preference")
    ) %>% 
  arrange(
    country_which, preference, ID
    ) %>% 
  relocate(
    preference, .before = contact
  ) 

Pre_BackgroundRaffle_Winners_R1_R2_R3 %>% 
  write_csv(
    file = "FanS2 Pre-cutoff background raffle winners FULL.csv"
    )

Pre_BackgroundRaffle_Winners_R1_R2_R3 %>% filter(preference == "Amazon.ca gift card")
```

## Background raffle winners (post-cutoff)

```{r}
#community background post-cutoff pool
Post_BackgroundRaffle_Pool <- "Fantasy Community_Contact_Spreadsheet.csv" %>% 
  read_csv(n_max = 1822) %>% 
  mutate(
    row = seq(from = 1, to = nrow(.), by = 1)
  ) %>% 
  relocate(row, .before = Email) %>% 
  filter(
    row > 1410,
    `Payment Eligible` == "Y" 
    ) %>% 
  select(
    ID,
    Email
  )
```

```{r}

#total number of winners

#total number of eligible participants divided by 14
winners.raw <- 3

#total number of winners to choose

winners.choose <- ceiling(winners.raw)

#print message
message("there will be ", winners.choose, " background post-cutoff winners")

```

```{r}
#community background post-cutoff winners and alternates
set.seed(12356)
Post_BackgroundRaffle_Winners <- sample(
  x = Post_BackgroundRaffle_Pool$ID, #the list of email addresses
  size = winners.choose, #the number of winners we decided on
  replace = FALSE #sample without replacement so the same person doesn't win twice. 
  )

for (i in 1:winners.choose){
  message("winner number ", i, " is ", Post_BackgroundRaffle_Winners[i])
}

tibble(winners = Post_BackgroundRaffle_Winners) %>% 
  write_csv(
    file = "FanS2 Post-cutoff background raffle winners.csv"
    )

```

## Main study raffle winners (post-cutoff)

```{r}
#Main post-cutoff raffle pool
Post_MainRaffle_Pool <- "Fantasy Community_Contact_Spreadsheet.csv" %>% 
  read_csv(n_max = 1822) %>% 
  mutate(
    row = seq(from = 1, to = nrow(.), by = 1)
  ) %>% 
  relocate(row, .before = Email) %>% 
  filter(
    row > 1410,
    `Sensical Answers?` == "Y"
    ) %>% 
  select(
    ID,
    Email
  )
```

```{r}

#total number of winners

#total number of eligible participants divided by 14
winners.raw <- 3

#total number of winners to choose

winners.choose <- ceiling(winners.raw)

#print message
message("there will be ", winners.choose, " main study post-cutoff winners")

```

```{r}
#community background post-cutoff winners and alternates
set.seed(12357)
Post_MainRaffle_Winners <- sample(
  x = Post_MainRaffle_Pool$Email, #the list of email addresses
  size = winners.choose, #the number of winners we decided on
  replace = FALSE #sample without replacement so the same person doesn't win twice. 
  )

for (i in 1:winners.choose){
  message("winner number ", i, " is ", Post_MainRaffle_Winners[i])
}

tibble(winners = Post_MainRaffle_Winners) %>% 
  write_csv(
    file = "FanS2 Post-cutoff Main raffle winners.csv"
    )

```

# Demographic Coding

## Currency, Residence, Study Source
```{r}
usable_data %>% 
  select(ID, Currency, Residence, `Study Source`) %>% 
  write_csv(file = "FanS2 Race Currency Residency Study Source Coding Ella.csv")

```

## Partner Number

```{r}
#PartnerNumber

usable_data %>% 
  select(ID, PartnerNumber) %>% 
  write_csv(file = "FanS2 Partner Number Coding Katya.csv")

```

## Relationship Status

```{r}

usable_data %>% 
  select(ID, Relstatusbutton_1, RelStatDescribe, relnumberdescribe, relapproach) %>% 
  write_csv(file = "FanS2 Relationship Status and Approach Coding.csv")

usable_data %>% 
  select(ID, sexapproach) %>% 
  arrange(ID) %>% 
  write_csv(file = "FanS2 Sexual Relationship Approach.csv")

```

## Disabilities
```{r}
#Disability_TEXT
usable_data %>% 
  select(ID, Diability_TEXT) %>% 
  filter(!is.na(Diability_TEXT)) %>% 
  write_csv(file= "FanS2 Disabilities Coding.csv")
```

## Participant Gender
```{r}
usable_data %>% 
  select(ID, ParticipantGender, GenderSex_MajMin, TransCisCategory, TransCisCategory_3_TEXT, TransCisCategory_4_TEXT, BinaryCategory, BinaryCategory_3_TEXT, BinaryCategory_4_TEXT) %>% 
  write_csv(file = "FanS2 GenderSex Coding Bella.csv")
```

## Sexual Identity/Orientation
```{r}
usable_data %>% 
  select(ID, SexIdentity) %>% 
  write_csv(file = "FanS2 Sexual Identity Orientation Coding Bianca.csv")
```
## Race/Ethnicity

```{r}
usable_data %>%
  select(ID, RaceEthnicity) %>% 
  write_csv(file = "FanS2 Race Ethnicity Coding Bianca.csv")

race_eth_coded <- "FanS2 Race Ethnicity Coding Bianca.xlsx" %>% read_excel(sheet = 1)

race_eth_coded <- race_eth_coded %>% 
  mutate(
    RaceEth_coded = recode(
      Bianca,
      WHI = "white",
      MLR = "Multiracial",
      WHJ = "Jewish, white",
      HLX = "Hispanic/Latinx",
      SAS = "South Asian",
      SEA = "Southeast Asian",
      ING = "Indigenous/First Nations/Native American/Pacific Islander",
      ASI = "Asian/Asian-American/Asian-Canadian",
      PAI = "Indigenous/First Nations/Native American/Pacific Islander",
      BLA = "Black",
      WHL = "Hispanic/Latinx, white",
      WME = "white, Middle Eastern",
      MEA = "Middle Eastern",
      AAC = "Asian/Asian-American/Asian-Canadian",
      JEW = "Jewish",
      WIN = "Indigenous, white"
    )
  ) %>% select(ID, RaceEth_coded)


usable_data <- left_join(usable_data, race_eth_coded, by = "ID")
```

## Religion

```{r}
usable_data %>% 
  select(ID, Religion) %>% 
  write_csv(file = "FanS2 Religion Coding Jada.csv")

religion_coded <- "FanS2 Religion Coding Jada.xlsx" %>% read_excel(sheet = 1)

religion_coded <- religion_coded %>% 
  mutate(
    religion_coded = recode(
      Jada,
        AGN = "Agnostic/Agnostic Atheist",
        AGA = "Agnostic/Agnostic Atheist",
        SPR = "Spiritual/Spiritual, Not Religious",
        SNR = "Spiritual/Spiritual, Not Religious",
        ANG = "Christian",
        BAP = "Christian",
        CAT = "Christian",
        CTC = "Christian",
        CHR = "Christian",
        NPC = "Christian",
        CRO = "Christian",
        CRE = "Christian",
        NDC = "Christian",
        EPI = "Christian",
        LUT = "Christian",
        MRM = "Christian",
        NAZ = "Christian",
        NOD = "Christian",
        PRS = "Christian",
        PRT = "Christian",
        RCT = "Christian",
        SDA = "Christian",
        APA = "Not Applicable/Prefer not to Answer",
        `NA` = "Not Applicable/Prefer not to Answer",
        ANM = "Animist",
        BUD = "Buddhist/Buddhist, Atheist",
        CRW = "Circle Worship",
        DAO = "Daoist",
        HND = "Hindu",
        INS = "Indigenous Spiritual",
        ISL = "Muslim",
        JEJ = "Jewish/Jewish, Atheist",
        MIX = "Multiple Religions",
        NOR = "Atheist/None/Areligious/Nonreligious",
        PAG = "Pagan/Wicca",
        SAT = "Satanic",
        SHN = "Shinto",
        SKH = "Sikh",
        TAO = "Taoist",
        TEN = "Tenrikyo",
        UNI = "Unitarian Universalist",
        WCA = "Pagan/Wicca"     
    )
  ) %>% select(ID, religion_coded)

usable_data <- left_join(usable_data, religion_coded, by = "ID")

```

## Past partner genders
```{r}
usable_data %>% 
  select(ID, PartnerGenders) %>% 
  write_csv(file = "FanS2 partner genders Coding Katya.csv")
```

## Current partner gender
```{r}
usable_data %>% 
  select(ID, partnergender) %>% 
  write_csv(file = "FanS2 current partner gender Coding Sara.csv")
```

## Fantasy Target

```{r}
usable_data %>% 
  select(ID, pfan.who, sfan.who) %>% 
  write_csv(file = "FanS2 fantasy target coding.csv")
```

# Factor Structure for the Fantasy Checklist

- Data set to work from: `usable_data`
- Fantasy checklist items: 
    - `sfan.checklist_#` (1 through 50; e.g., `sfan.checklist_1`)
    - `pfan.checklist_#` 

## Missingness

**Note for Jay:** your goal with junk is to find out how much missing data we have for each fantasy checklist item. 

```{r}
## Getting the data
p_checklist<-usable_data %>%  
  select(c(110:159)) # Selected only the partnered fantasy checklist and ID

s_checklist<-usable_data %>%  
  select(c(173:222)) # Selected only the solitary fantasy checklist and ID

# Partnered fantasy, count of all NAs
na.p<-p_checklist %>% 
  summarise_all(~ sum(is.na(.))) %>% # Count of all the na per variable for partnered fantasy
  pivot_longer(cols = starts_with("pfan")) # pivoting the data
na.p$percent<-na.p$value/563*100 # making it a percent

p_checklist_participants<-p_checklist
p_checklist_participants$p.na<-rowSums(is.na(p_checklist)) # Count of the na values per rows, added to data frame
p_checklist_participants$p.na.percent<-p_checklist_participants$p.na/50*100 # Making it into a percent

```

Histogram for missing data by variable for partnered fantasy
```{r}
ggplot(na.p, aes(x=percent))+
  geom_histogram()

table(na.p$value) # Table of values (I used the absolute count because it made more sense to look at)
```

Histogram for missing data by participant for partnered fantasy
```{r}
ggplot(p_checklist_participants, aes(x=p.na.percent))+
  geom_histogram()

table(p_checklist_participants$p.na.percent) # Table of values (I used the percentage of missing data per participant)
```


```{r}
# Solitary fantasy
na.s<-s_checklist %>% 
  summarise_all(~ sum(is.na(.))) %>% # Count of all the na per variable for solitary fantasy
  pivot_longer(cols = starts_with("sfan")) # pivoting the data
na.s$percent<-na.s$value/563*100 # making it a percent

s_checklist_participants<-s_checklist
s_checklist_participants$s.na<-rowSums(is.na(s_checklist)) # Count of the na values per rows, added to data frame
s_checklist_participants$s.na.percent<-s_checklist_participants$s.na/50*100 # Making it into a percent

```

Histogram for missing data by variable for solitary fantasy
```{r}
ggplot(na.s, aes(x=percent))+
  geom_histogram()

table(na.s$value) # Table of values (I used the absolute count because it made more sense to look at)
```

Histogram for missing data by participant for solitary fantasy
```{r}
ggplot(s_checklist_participants, aes(x=s.na.percent))+
  geom_histogram()

table(s_checklist_participants$s.na.percent) # Table of values (I used the percentage of missing data per participant)
```

Looking at both
```{r}
full_checklists<-usable_data %>%  
  select(c(1,110:159,173:222)) # Gathering both checklists

full_checklists$na<-rowSums(is.na(full_checklists)) # Counting all the NAs

ggplot(full_checklists, aes(x=na))+
  geom_histogram()

table(full_checklists$na)
```
## Removing the participants who have no data for one or both conditions
```{r}
p_checklist_clean<-p_checklist[-c(38,39,40,41,172,260,282,315,329,395,415,446,460,469,475,476,481,488,501,502,506,543,545,549,560,563), ]

s_checklist_clean<-s_checklist[-c(38,39,40,41,172,260,282,315,329,395,415,446,460,469,475,476,481,488,501,502,506,543,545,549,560,563), ]
```

## Mardia's Test, partnered fantasy 

I am running Mardia's test on the data. First, I'm going to grab a subset of the data (only the partnered fantasy checklist). Then I will run the actual test. 

```{r}
mardia(p_checklist_clean, na.rm = T)
```

These results suggest that this data is non-normal, so I will calculate polychoric correlation matrices. 

## Mardia's Test, solitary fantasy

I'm rerunning the same analysis, but using the solitary fantasy.

```{r}
mardia(s_checklist_clean, na.rm = T)
```

These results show that the solitary checklist is also non-normal (especially the Q-Q plot).

## Calculating polychoric correlation matrices - psych package

Using the subsets I've created above, I will now create two polychoric correlation matrices, using the polychoric function from the psych package. I couldn't figure out what they were doing for missing data. 

```{r}
# Partnered fantasy
p_check_poly_psych<-polychoric(p_checklist_clean,
                               smooth = T, # Smoothing the data
                             # global = F, # running the analysis using the local values
                         )

p_check_matrix_psych<-p_check_poly_psych$rho # Selecting the rho values, so that we have a correlation matrix

# Solitary fantasy
s_check_poly_psych<-polychoric(s_checklist_clean, 
                               smooth = T, # Smoothing the data
                        # global = F, # running the analysis using the local values
                         )

s_check_matrix_psych<-s_check_poly_psych$rho # Selecting the rho values, so that we have a correlation matrix
```

## Calculating polychoric correlation matrices - Lavaan package

Partnered fantasy
```{r}
p_check_poly_lavaan<-lavCor(p_checklist_clean, 
                            ordered = colnames(p_checklist_clean), # This tells it that the variables are ordinal
                            missing = "pairwise", #This does pairwise deletion 
                            output = "cor", #This outputs a correlation matrix
                            cor.smooth=T
                            )


## The matrices are not the same, but they're close, and honestly, that's good enough

part_values_psych<-p_check_matrix_psych[lower.tri(p_check_matrix_psych)]
part_values_lavaan<-p_check_poly_lavaan[lower.tri(p_check_poly_lavaan)]
same_p<-part_values_psych-part_values_lavaan
mean(abs(same_p))

range(abs(same_p))
```

Solitary fantasy
```{r}
s_check_poly_lavaan<-lavCor(s_checklist_clean, 
                            ordered = colnames(s_checklist_clean), # This tells it that the variables are ordinal
                            missing = "pairwise", #This does pairwise deletion 
                            output = "cor", #This outputs a correlation matrix
                            cor.smooth=T
                            )

sol_values_psych<-s_check_matrix_psych[lower.tri(s_check_matrix_psych)]
sol_values_lavaan<-s_check_poly_lavaan[lower.tri(s_check_poly_lavaan)]
same_s<-sol_values_psych-sol_values_lavaan
mean(abs(same_s))

range(abs(same_s))
```

# Parallel analysis

## Partnered fantasy

Using the subsets I've created above, I will now create two polychoric correlation matrices, using the polychoric function from the lavaan package. 

```{r}
# Partnered fantasy
fa.parallel(p_check_poly_lavaan, n.obs=537, fm = "uls", n.iter = 20, cor = "poly")
```
## Solitary fantasy

```{r}
# Partnered fantasy
fa.parallel(s_check_poly_lavaan, n.obs=537, fm = "uls", n.iter = 20, cor = "poly")
```

# Running EFAs 

## Partnered fantasy 

Making the models (code stolen from the internet).

```{r}
f1 <- '
efa("efa")*f1 =~ pfan.checklist_1 + pfan.checklist_2 + pfan.checklist_3 + pfan.checklist_4 + pfan.checklist_5 +
                  pfan.checklist_6 + pfan.checklist_7 + pfan.checklist_8 + pfan.checklist_9 + pfan.checklist_10 +
                  pfan.checklist_11 + pfan.checklist_12 + pfan.checklist_13 + pfan.checklist_14 + pfan.checklist_15 +
                  pfan.checklist_16 + pfan.checklist_17 + pfan.checklist_18 + pfan.checklist_19 + pfan.checklist_20 +
                  pfan.checklist_21 + pfan.checklist_22 + pfan.checklist_23 + pfan.checklist_24 + pfan.checklist_25 +
                  pfan.checklist_26 + pfan.checklist_27 + pfan.checklist_28 + pfan.checklist_29 + pfan.checklist_30 +
                  pfan.checklist_31 + pfan.checklist_32 + pfan.checklist_33 + pfan.checklist_34 + pfan.checklist_35 +
                  pfan.checklist_36 + pfan.checklist_37 + pfan.checklist_38 + pfan.checklist_39 + pfan.checklist_40 +
                  pfan.checklist_41 + pfan.checklist_42 + pfan.checklist_43 + pfan.checklist_44 + pfan.checklist_45 +
                  pfan.checklist_46 + pfan.checklist_47 + pfan.checklist_48 + pfan.checklist_49 + pfan.checklist_50
     '   

f2 <- '
efa("efa")*f1+
efa("efa")*f2=~ pfan.checklist_1 + pfan.checklist_2 + pfan.checklist_3 + pfan.checklist_4 + pfan.checklist_5 +
                  pfan.checklist_6 + pfan.checklist_7 + pfan.checklist_8 + pfan.checklist_9 + pfan.checklist_10 +
                  pfan.checklist_11 + pfan.checklist_12 + pfan.checklist_13 + pfan.checklist_14 + pfan.checklist_15 +
                  pfan.checklist_16 + pfan.checklist_17 + pfan.checklist_18 + pfan.checklist_19 + pfan.checklist_20 +
                  pfan.checklist_21 + pfan.checklist_22 + pfan.checklist_23 + pfan.checklist_24 + pfan.checklist_25 +
                  pfan.checklist_26 + pfan.checklist_27 + pfan.checklist_28 + pfan.checklist_29 + pfan.checklist_30 +
                  pfan.checklist_31 + pfan.checklist_32 + pfan.checklist_33 + pfan.checklist_34 + pfan.checklist_35 +
                  pfan.checklist_36 + pfan.checklist_37 + pfan.checklist_38 + pfan.checklist_39 + pfan.checklist_40 +
                  pfan.checklist_41 + pfan.checklist_42 + pfan.checklist_43 + pfan.checklist_44 + pfan.checklist_45 +
                  pfan.checklist_46 + pfan.checklist_47 + pfan.checklist_48 + pfan.checklist_49 + pfan.checklist_50
     '   
f3 <- '
efa("efa")*f1+
efa("efa")*f2+
efa("efa")*f3=~ pfan.checklist_1 + pfan.checklist_2 + pfan.checklist_3 + pfan.checklist_4 + pfan.checklist_5 +
                  pfan.checklist_6 + pfan.checklist_7 + pfan.checklist_8 + pfan.checklist_9 + pfan.checklist_10 +
                  pfan.checklist_11 + pfan.checklist_12 + pfan.checklist_13 + pfan.checklist_14 + pfan.checklist_15 +
                  pfan.checklist_16 + pfan.checklist_17 + pfan.checklist_18 + pfan.checklist_19 + pfan.checklist_20 +
                  pfan.checklist_21 + pfan.checklist_22 + pfan.checklist_23 + pfan.checklist_24 + pfan.checklist_25 +
                  pfan.checklist_26 + pfan.checklist_27 + pfan.checklist_28 + pfan.checklist_29 + pfan.checklist_30 +
                  pfan.checklist_31 + pfan.checklist_32 + pfan.checklist_33 + pfan.checklist_34 + pfan.checklist_35 +
                  pfan.checklist_36 + pfan.checklist_37 + pfan.checklist_38 + pfan.checklist_39 + pfan.checklist_40 +
                  pfan.checklist_41 + pfan.checklist_42 + pfan.checklist_43 + pfan.checklist_44 + pfan.checklist_45 +
                  pfan.checklist_46 + pfan.checklist_47 + pfan.checklist_48 + pfan.checklist_49 + pfan.checklist_50
     '  
f4 <- '
efa("efa")*f1+
efa("efa")*f2+
efa("efa")*f3+
efa("efa")*f4=~ pfan.checklist_1 + pfan.checklist_2 + pfan.checklist_3 + pfan.checklist_4 + pfan.checklist_5 +
                  pfan.checklist_6 + pfan.checklist_7 + pfan.checklist_8 + pfan.checklist_9 + pfan.checklist_10 +
                  pfan.checklist_11 + pfan.checklist_12 + pfan.checklist_13 + pfan.checklist_14 + pfan.checklist_15 +
                  pfan.checklist_16 + pfan.checklist_17 + pfan.checklist_18 + pfan.checklist_19 + pfan.checklist_20 +
                  pfan.checklist_21 + pfan.checklist_22 + pfan.checklist_23 + pfan.checklist_24 + pfan.checklist_25 +
                  pfan.checklist_26 + pfan.checklist_27 + pfan.checklist_28 + pfan.checklist_29 + pfan.checklist_30 +
                  pfan.checklist_31 + pfan.checklist_32 + pfan.checklist_33 + pfan.checklist_34 + pfan.checklist_35 +
                  pfan.checklist_36 + pfan.checklist_37 + pfan.checklist_38 + pfan.checklist_39 + pfan.checklist_40 +
                  pfan.checklist_41 + pfan.checklist_42 + pfan.checklist_43 + pfan.checklist_44 + pfan.checklist_45 +
                  pfan.checklist_46 + pfan.checklist_47 + pfan.checklist_48 + pfan.checklist_49 + pfan.checklist_50
     '  

f5 <- '
efa("efa")*f1+
efa("efa")*f2+
efa("efa")*f3+
efa("efa")*f4+
efa("efa")*f5=~ pfan.checklist_1 + pfan.checklist_2 + pfan.checklist_3 + pfan.checklist_4 + pfan.checklist_5 +
                  pfan.checklist_6 + pfan.checklist_7 + pfan.checklist_8 + pfan.checklist_9 + pfan.checklist_10 +
                  pfan.checklist_11 + pfan.checklist_12 + pfan.checklist_13 + pfan.checklist_14 + pfan.checklist_15 +
                  pfan.checklist_16 + pfan.checklist_17 + pfan.checklist_18 + pfan.checklist_19 + pfan.checklist_20 +
                  pfan.checklist_21 + pfan.checklist_22 + pfan.checklist_23 + pfan.checklist_24 + pfan.checklist_25 +
                  pfan.checklist_26 + pfan.checklist_27 + pfan.checklist_28 + pfan.checklist_29 + pfan.checklist_30 +
                  pfan.checklist_31 + pfan.checklist_32 + pfan.checklist_33 + pfan.checklist_34 + pfan.checklist_35 +
                  pfan.checklist_36 + pfan.checklist_37 + pfan.checklist_38 + pfan.checklist_39 + pfan.checklist_40 +
                  pfan.checklist_41 + pfan.checklist_42 + pfan.checklist_43 + pfan.checklist_44 + pfan.checklist_45 +
                  pfan.checklist_46 + pfan.checklist_47 + pfan.checklist_48 + pfan.checklist_49 + pfan.checklist_50
     '  
f6 <- '
efa("efa")*f1+
efa("efa")*f2+
efa("efa")*f3+
efa("efa")*f4+
efa("efa")*f5+
efa("efa")*f6=~ pfan.checklist_1 + pfan.checklist_2 + pfan.checklist_3 + pfan.checklist_4 + pfan.checklist_5 +
                  pfan.checklist_6 + pfan.checklist_7 + pfan.checklist_8 + pfan.checklist_9 + pfan.checklist_10 +
                  pfan.checklist_11 + pfan.checklist_12 + pfan.checklist_13 + pfan.checklist_14 + pfan.checklist_15 +
                  pfan.checklist_16 + pfan.checklist_17 + pfan.checklist_18 + pfan.checklist_19 + pfan.checklist_20 +
                  pfan.checklist_21 + pfan.checklist_22 + pfan.checklist_23 + pfan.checklist_24 + pfan.checklist_25 +
                  pfan.checklist_26 + pfan.checklist_27 + pfan.checklist_28 + pfan.checklist_29 + pfan.checklist_30 +
                  pfan.checklist_31 + pfan.checklist_32 + pfan.checklist_33 + pfan.checklist_34 + pfan.checklist_35 +
                  pfan.checklist_36 + pfan.checklist_37 + pfan.checklist_38 + pfan.checklist_39 + pfan.checklist_40 +
                  pfan.checklist_41 + pfan.checklist_42 + pfan.checklist_43 + pfan.checklist_44 + pfan.checklist_45 +
                  pfan.checklist_46 + pfan.checklist_47 + pfan.checklist_48 + pfan.checklist_49 + pfan.checklist_50
     ' 
```

Doing the EFAs
```{r}

efa_f1 <- 
  cfa(model = f1, # specifying the model
      sample.cov = p_check_poly_lavaan, # using the polychoric matrix
      rotation = "geomin", # specifying the rotation
      estimator = "ULS", # specifying the estimator
      ordered = TRUE, # not sure if I need to have this
      missing="pairwise", # doing pairwise deletion
      sample.nobs = 537, # the number of observations
      control=list(iter.max=1000) # the maximum amount of iterations
      )

# Repeating the code for the other models
efa_f2 <- 
  cfa(model = f2,
      sample.cov = p_check_poly_lavaan,
      rotation = "geomin",
      estimator = "ULS",
      ordered = TRUE,
      missing="pairwise",
      sample.nobs = 537,
      control=list(iter.max=1000)
      )


efa_f3 <- 
   cfa(model = f3,
      sample.cov = p_check_poly_lavaan,
      rotation = "geomin",
      estimator = "ULS",
      ordered = TRUE,
      missing="pairwise",
      sample.nobs = 537,
      control=list(iter.max=1000)
      )

efa_f4 <- 
    cfa(model = f4,
      sample.cov = p_check_poly_lavaan,
      rotation = "geomin",
      estimator = "ULS",
      ordered = TRUE,
      missing="pairwise",
      sample.nobs = 537,
      control=list(iter.max=1000)
      )

efa_f5 <- 
   cfa(model = f5,
      sample.cov = p_check_poly_lavaan,
      rotation = "geomin",
      estimator = "ULS",
      ordered = TRUE,
      missing="pairwise",
      sample.nobs = 537,
      control=list(iter.max=1000)
      )

efa_f6 <- 
    cfa(model = f6,
      sample.cov = p_check_poly_lavaan,
      rotation = "geomin",
      estimator = "ULS",
      ordered = TRUE,
      missing="pairwise",
     sample.nobs = 537,
      control=list(iter.max=1000)
      )

```

Wrangling and summarizing. 

```{r}

# define the fit measures
fit_measures_robust <- c("chisq", "df", "tli",
                         "cfi", "rmsea", "rmsea.ci.lower","rmsea.ci.upper")


# collect them for each model
rbind(
  fitmeasures(efa_f1, fit_measures_robust),
  fitmeasures(efa_f2, fit_measures_robust),
  fitmeasures(efa_f3, fit_measures_robust),
  fitmeasures(efa_f4, fit_measures_robust),
  fitmeasures(efa_f5, fit_measures_robust),
  fitmeasures(efa_f6, fit_measures_robust)) %>% 
  # wrangle
  data.frame() %>% 
  mutate(chisq  = round(chisq, digits = 0),
         df            = as.integer(df)) %>% 
  mutate_at(vars(tli:rmsea.ci.upper), ~round(., digits =  3))
```
